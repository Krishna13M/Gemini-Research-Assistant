# ğŸ” Gemini Research Assistant

A document-based AI assistant built using Streamlit and Gemini 2.5 Flash. Upload a PDF or TXT file, ask questions about it, challenge yourself with comprehension tests, and ensure every answer is grounded in the original document.

---

## ğŸš€ Features

- âœ… **Document Upload** â€“ Supports `.pdf` and `.txt` files (up to 10MB)
- ğŸ“ **Auto-Summary** â€“ Generates a concise 150-word summary of the uploaded document
- ğŸ” **Ask Anything** â€“ Ask questions strictly based on the uploaded content
- ğŸ“Œ **Source Verification** â€“ Ensures answers are directly supported by the document
- ğŸ§  **Challenge Mode** â€“ Automatically generates and evaluates comprehension questions
- ğŸ’¾ **Memory Management** â€“ Maintains summary and recent Q&A history for better context

---
## ğŸ§  Architecture / Reasoning Flow

This app uses a **modular, memory-aware reasoning architecture** powered by Google Gemini 2.5 Flash and Streamlit.

### 1. ğŸ“„ Document Upload & Parsing
- Users upload a `.pdf` or `.txt` file.
- File is parsed using:
  - `PyPDF2` for PDFs (text-based only)
  - UTF-8 decoding for TXT files
- File size capped at **10MB** to stay within processing limits.

### 2. ğŸ“ Auto-Summary
- Once uploaded, a **150-word summary** is generated using Gemini:
  - Prompted with the first ~30,000 characters of the document
  - Provides a high-level overview of key content

---

### 3. ğŸ” Ask Anything (Document Q&A)
- Users ask natural-language questions about the document.
- The model prompt includes:
  - ğŸ§¾ **Primary source** (first ~15,000 chars of document)
  - ğŸ§  **Conversation context**: summary + last 2 verified Q&A pairs
- Gemini is instructed to:
  - **Answer strictly based on the document**
  - Use memory only to understand follow-ups â€” not as a fact source

#### âœ”ï¸ Verification & Justification
1. Gemini's answer is validated:
   - Prompted again to confirm: "Is this directly supported by the source?"
2. If supported:
   - A **direct quote** is extracted from the source text to justify the answer
   - The answer + quote is shown to the user
   - Itâ€™s stored in memory for context in future prompts
3. If not supported:
   - The system returns: _"I couldn't find supporting evidence in the document"_

---

### 4. ğŸ§  Challenge Me (Comprehension Test)
- Clicking â€œGenerate Questionsâ€ prompts Gemini to create 3 QA pairs.
- Users write their own answers.
- Gemini evaluates responses using 5 criteria:
  1. **DOCUMENT RELEVANCE**: Does the question relate to the document?
  2. **ANSWER ACCURACY**: Correct / Partially Correct / Incorrect
  3. **SCORE**: 1â€“10
  4. **TEXT EVIDENCE**: Direct quote (if any)
  5. **SUGGESTIONS**: Feedback for improving alignment

---

### 5. ğŸ’¾ Memory Management (Stateful Context)
- Stored in `st.session_state.memory`
  - `summary`: Current document summary (auto-updated)
  - `recent`: Last two verified Q&A pairs
- Ensures follow-up queries are **context-aware** but not hallucinated.

---

## ğŸ§° Technologies Used

- [Streamlit](https://streamlit.io/) â€“ for building the web app
- [Google Gemini API](https://ai.google.dev/) â€“ for text generation and reasoning
- [PyPDF2](https://pypi.org/project/PyPDF2/) â€“ for PDF text extraction
- [python-dotenv](https://pypi.org/project/python-dotenv/) â€“ for environment variable management

---

## âš™ï¸ Setup Instructions

### 1. **Clone the repository**

```bash
git clone https://github.com/yourusername/gemini-research-assistant.git
cd gemini-research-assistant
```

### 2. **Create a virtual environment (recommended)**
```
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 3. **Install dependencies**

```
pip install -r requirements.txt
```

### 4. **Add your Gemini API Key**

Create a .env file in the root directory:
```
GEMINI_API_KEY=your_google_gemini_api_key
```
### 5. **Run the application**

```
streamlit run app.py
```
Then open http://localhost:8501 in your browser.
